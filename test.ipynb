{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619ac505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sockets --user\n",
    "# %pip install torch torchvision torchaudio --user\n",
    "# %pip install facenet-pytorch --user\n",
    "# %pip install matplotlib --user\n",
    "# %pip install scikit-learn --user\n",
    "# %pip install numpy --user\n",
    "# %pip install opencv-python --user\n",
    "# %pip install google-auth gspread --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d6d065-45f9-4306-9e7b-aef1a19c3184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "import base64\n",
    "import io as BytesIO\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from datetime import datetime\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f9dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272a01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MTCNN face detector\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "detector = MTCNN(keep_all=False, device=device)\n",
    "# Load the pretrained FaceNet model\n",
    "embedder = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc03e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base64_to_opencv_image(base64_str):\n",
    "    try:\n",
    "        # Decode the base64 image\n",
    "        img_data = base64.b64decode(base64_str.split(',')[1])\n",
    "        # Convert bytes to numpy array\n",
    "        np_array = np.frombuffer(img_data, np.uint8)\n",
    "        # Decode numpy array to image\n",
    "        image = cv.imdecode(np_array, cv.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            raise ValueError(\"Could not decode image.\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in base64_to_opencv_image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_date_time(iso_string):\n",
    "    # Remove the 'Z' if present (timezone designator)\n",
    "    iso_string = iso_string.rstrip('Z')\n",
    "\n",
    "    # Parse the ISO 8601 string\n",
    "    try:\n",
    "        date_time = datetime.fromisoformat(iso_string)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\"Invalid ISO 8601 format\") from e\n",
    "\n",
    "    # Format the date as dd/mm/yy\n",
    "    formatted_date = date_time.strftime(\"%d/%m/%y\")\n",
    "\n",
    "    # Format the time as hh:mm:ss\n",
    "    formatted_time = date_time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    return formatted_date, formatted_time\n",
    "\n",
    "\n",
    "def addName(newInfo, sheet):\n",
    "    # Find the last row with data in the column (e.g., column A)\n",
    "    column_values = sheet.col_values(1)  # Fetch all values in column A\n",
    "    last_row = len(column_values) + 1  # Get the index of the next row\n",
    "\n",
    "    # Data to be added\n",
    "    new_data = [[newInfo]]\n",
    "\n",
    "    # Update the cell in the next available row in column A\n",
    "    cell_range = f'A{last_row}'  # Adjust the column letter if needed\n",
    "    try:\n",
    "        sheet.update(cell_range, new_data)\n",
    "        print(f\"Added data to row {last_row} in column A.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating Google Sheet: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e4f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FACELOADING:\n",
    "    def __init__(self, target_size=(160, 160)):\n",
    "        self.target_size = target_size\n",
    "        self.detector = MTCNN()\n",
    "    \n",
    "    def resize_image(self, img):\n",
    "        return cv.resize(img, self.target_size)\n",
    "\n",
    "    def extract_face(self, filename):\n",
    "        img = cv.imread(filename)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize the image before face detection\n",
    "        img = self.resize_image(img)\n",
    "        \n",
    "        # Detect faces\n",
    "        results = self.detector.detect(img, landmarks=False)\n",
    "        \n",
    "        # Check if results contain faces\n",
    "        if results is not None and len(results) > 0:\n",
    "            boxes = results[0]  # Extract bounding boxes from the results\n",
    "            faces = []\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = [int(num) for num in box]\n",
    "                face = img[y1:y2, x1:x2]\n",
    "                face_arr = cv.resize(face, self.target_size)\n",
    "                faces.append(face_arr)\n",
    "            return faces\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def process_image(self, filename):\n",
    "        faces = self.extract_face(filename)\n",
    "        if faces is not None:\n",
    "            # Assuming that you may want to get embeddings or process the faces further\n",
    "            return faces\n",
    "        else:\n",
    "            print(\"No face detected.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60cdb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained FaceNet model\n",
    "embedder = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "detector = MTCNN(keep_all=False)  # Initialize MTCNN for face detection\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    detector = MTCNN(keep_all=False)  # Initialize MTCNN for face detection\n",
    "    model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "    face_img = cv.cvtColor(face_img, cv.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    face_img = torch.tensor(face_img).float()  # Convert to PyTorch tensor\n",
    "    face_img = face_img.permute(2, 0, 1)  # Change dimensions to (C, H, W)\n",
    "    face_img = face_img.unsqueeze(0)  # Add batch dimension\n",
    "    face_img = (face_img - 127.5) / 128.0  # Normalize image\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_img)  # Get the embedding\n",
    "    return embedding.squeeze().numpy()  # Convert to NumPy array\n",
    "\n",
    "def update_npz(npz_file, new_embeddings, new_labels):\n",
    "    # Load the existing .npz file\n",
    "    data = np.load(npz_file, allow_pickle=True)\n",
    "    \n",
    "    # Extract the existing arrays\n",
    "    existing_embeddings = data['embeddings'] if 'embeddings' in data else np.empty((0, new_embeddings.shape[1]))\n",
    "    existing_labels = data['labels'] if 'labels' in data else np.empty((0,), dtype=object)\n",
    "    \n",
    "    # Append new data\n",
    "    updated_embeddings = np.concatenate((existing_embeddings, new_embeddings), axis=0)\n",
    "    updated_labels = np.concatenate((existing_labels, new_labels), axis=0)\n",
    "    \n",
    "    # Save the updated arrays back into the .npz file\n",
    "    np.savez_compressed(npz_file, embeddings=updated_embeddings, labels=updated_labels)\n",
    "\n",
    "def retrain_model(npz_file, model_file):\n",
    "    # Load data from .npz file\n",
    "    data = np.load(npz_file, allow_pickle=True)\n",
    "    embeddings = data['embeddings']\n",
    "    labels = data['labels']\n",
    "\n",
    "    # Check if data is valid\n",
    "    if embeddings.size == 0 or labels.size == 0:\n",
    "        raise ValueError(\"Loaded data is empty. Ensure the .npz file contains embeddings and labels.\")\n",
    "\n",
    "    # Encode labels\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "\n",
    "    # Train the SVM model\n",
    "    model = SVC(kernel='linear', probability=True)  # You can adjust the kernel and parameters\n",
    "    model.fit(embeddings, encoded_labels)\n",
    "\n",
    "    # Save the trained model\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(f\"Model retrained and saved to {model_file}\")\n",
    "\n",
    "def recognise(pkl_file, np_file, embeddings):\n",
    "    # Load the embeddings and labels\n",
    "    faces_embeddings = np.load(np_file)\n",
    "    X = faces_embeddings['embeddings']  # Assuming embeddings are stored under 'arr_0'\n",
    "    Y = faces_embeddings['labels']  # Assuming labels are stored under 'arr_1'\n",
    "\n",
    "    # Load the trained model\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Fit the label encoder on existing labels\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "\n",
    "    # Predict the class for each embedding\n",
    "    predictions = model.predict(embeddings)\n",
    "    \n",
    "    # Convert predictions to class names\n",
    "    final_names = encoder.inverse_transform(predictions)\n",
    "\n",
    "    print(f\"Predicted labels: {predictions}\")\n",
    "    print(f\"Final names: {final_names}\")\n",
    "\n",
    "    return final_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a62caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticating google sheets api\n",
    "\n",
    "# Define the scopes\n",
    "scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \n",
    "          \"https://www.googleapis.com/auth/drive\"]\n",
    "# Create credentials object\n",
    "creds = Credentials.from_service_account_file(\"proj-sheets.json\", scopes=scopes)\n",
    "# Authenticate and create a client\n",
    "client = gspread.authorize(creds)\n",
    "sheet_id = \"1nzL6dv1ue9dwXdosWSLAeos_dPSttadJOiL9G8DgU80\"\n",
    "\n",
    "# Open the spreadsheet by key\n",
    "sheets = client.open_by_key(sheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6072a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f3de52",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 10048] error while attempting to bind on address ('127.0.0.1', 8765): only one usage of each socket address (protocol/network address/port) is normally permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m server\u001b[38;5;241m.\u001b[39mwait_closed()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Run the server\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m start_server()\n",
      "Cell \u001b[1;32mIn[14], line 79\u001b[0m, in \u001b[0;36mstart_server\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_server\u001b[39m():\n\u001b[1;32m---> 79\u001b[0m     server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m websockets\u001b[38;5;241m.\u001b[39mserve(handle_connection, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m8765\u001b[39m)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebSocket server started on ws://localhost:8765\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m server\u001b[38;5;241m.\u001b[39mwait_closed()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\websockets\\legacy\\server.py:1116\u001b[0m, in \u001b[0;36mServe.__await_impl__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__await_impl__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m WebSocketServer:\n\u001b[1;32m-> 1116\u001b[0m     server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_server()\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mws_server\u001b[38;5;241m.\u001b[39mwrap(server)\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mws_server\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\asyncio\\base_events.py:1572\u001b[0m, in \u001b[0;36mBaseEventLoop.create_server\u001b[1;34m(self, protocol_factory, host, port, family, flags, sock, backlog, ssl, reuse_address, reuse_port, ssl_handshake_timeout, ssl_shutdown_timeout, start_serving)\u001b[0m\n\u001b[0;32m   1570\u001b[0m                 logger\u001b[38;5;241m.\u001b[39mwarning(msg)\n\u001b[0;32m   1571\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(err\u001b[38;5;241m.\u001b[39merrno, msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sockets:\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not bind on any address out of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1576\u001b[0m                   \u001b[38;5;241m%\u001b[39m ([info[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m infos],))\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 10048] error while attempting to bind on address ('127.0.0.1', 8765): only one usage of each socket address (protocol/network address/port) is normally permitted"
     ]
    }
   ],
   "source": [
    "with open('names.txt', 'r') as file:\n",
    "    names = file.read().splitlines()\n",
    "with open('courses.txt', 'r') as file:\n",
    "    courses = file.read().splitlines()\n",
    "\n",
    "\n",
    "async def handle_connection(websocket, path):\n",
    "    async for message in websocket:\n",
    "        data = json.loads(message)\n",
    "        print(f\"Received data: {data}\")  # Add this line for debugging\n",
    "\n",
    "        if data['type'] == 'photo':\n",
    "            try:\n",
    "                image_data = data['image']\n",
    "                image = base64_to_opencv_image(image_data)\n",
    "                cv.imwrite('captured_image.jpg', image)\n",
    "                \n",
    "                date, time = extract_date_time(data['date'])\n",
    "                name = recognise('captured_image.jpg', 'svm_model.pkl')\n",
    "                print(f\"Recognised name: {name}\")  # Add this line for debugging\n",
    "                \n",
    "                if name in names:\n",
    "                    index = names.index(name)\n",
    "                    sheet = client.open('Your Sheet Name').worksheet(courses[index])\n",
    "                    row_header = name\n",
    "                    column_header = date\n",
    "                    \n",
    "                    row_cell = sheet.find(row_header)\n",
    "                    column_cell = sheet.find(column_header)\n",
    "                    \n",
    "                    if row_cell and column_cell:\n",
    "                        row_index = row_cell.row\n",
    "                        column_index = column_cell.col\n",
    "                        sheet.update(range_name=f'{column_header}{row_index}', values=['Present'])\n",
    "                    else:\n",
    "                        print(f\"Row or column header not found: {row_header}, {column_header}\")  # Changed from display to print\n",
    "                else:\n",
    "                    print(f\"Name not found in list: {name}\")  # Changed from display to print\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing photo_with_info: {e}\")  # Changed from display to print\n",
    "\n",
    "        elif data['type'] == 'photo_with_info':\n",
    "            try:\n",
    "                image_data = data['image']\n",
    "                name = data['name']\n",
    "                course = data['course']\n",
    "                \n",
    "                names.append(name)\n",
    "                courses.append(course)\n",
    "                \n",
    "                sheet = client.open('Your Sheet Name').worksheet(course)\n",
    "                addName(name, sheet)\n",
    "                \n",
    "                image = base64_to_opencv_image(image_data)\n",
    "                \n",
    "                existing_folder_path = \"dataset\"\n",
    "                new_folder_name = name\n",
    "                new_folder_path = os.path.join(existing_folder_path, new_folder_name)\n",
    "                os.makedirs(new_folder_path, exist_ok=True)\n",
    "                \n",
    "                image_path = os.path.join(new_folder_path, f'{name}.jpg')\n",
    "                cv.imwrite(image_path, image)\n",
    "                \n",
    "                faceloader = FACELOADING()\n",
    "                X = faceloader.process_image(f'dataset/{name}.jpg')\n",
    "                EMBEDDED_X = []\n",
    "                for img in X:\n",
    "                    embedding = get_embedding(img)\n",
    "                    EMBEDDED_X.append(embedding)\n",
    "                EMBEDDED_X = np.asarray(EMBEDDED_X)\n",
    "                update_npz('faces_embeddings.npz', EMBEDDED_X, name)\n",
    "                retrain_model('faces_embeddings.npz', 'model.pkl')\n",
    "                with open('names.txt', 'w') as file:\n",
    "                    file.writelines(names)\n",
    "                with open('courses.txt', 'w') as file:\n",
    "                    file.writelines(courses)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing photo_with_info: {e}\")  # Changed from display to print\n",
    "\n",
    "\n",
    "async def start_server():\n",
    "    server = await websockets.serve(handle_connection, 'localhost', 8765)\n",
    "    print(\"WebSocket server started on ws://localhost:8765\")\n",
    "    await server.wait_closed()\n",
    "\n",
    "# Run the server\n",
    "await start_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54ed74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
